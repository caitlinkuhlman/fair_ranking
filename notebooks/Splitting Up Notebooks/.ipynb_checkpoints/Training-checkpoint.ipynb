{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.26726291  0.79229534  0.48719052 ..., -0.61734258 -0.67537433  1.        ]\n",
      " [-0.26726291  0.79229534 -1.18384943 ...,  0.25130789 -0.01195442  0.        ]\n",
      " [-0.26726291  0.79229534 -0.18122546 ..., -0.34150796 -0.85266957  1.        ]\n",
      " ..., \n",
      " [-0.26726291  0.79229534 -0.24806706 ..., -0.49085488 -0.70526847  0.        ]\n",
      " [-0.26726291  0.79229534 -1.31753263 ..., -0.67068076  0.34769506  0.        ]\n",
      " [-0.26726291  0.79229534  0.48719052 ...,  0.         -0.43392168  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "X = pickle.load( open( \"x.p\", \"rb\" ) )\n",
    "y = pickle.load( open( \"y.p\", \"rb\" ) )\n",
    "#g = pickle.load( open( \"g.p\", \"rb\" ) )\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X_all_train, X_test, y_all_train, y_test = train_test_split( X, y, test_size=0.4, random_state=0)\n",
    "X_train, X_cal, y_train, y_cal = train_test_split( X_all_train, y_all_train, test_size=0.5, random_state=0)\n",
    "\n",
    "#Remove the groups from the dataset X. We do this after splitting so that group identities are preserved\n",
    "X_all_train_no_g = np.delete(X_all_train, -1, axis=1)\n",
    "X_all_train_g = np.take(X_all_train, -1, axis=1)\n",
    "\n",
    "X_train_no_g = np.delete(X_train, -1, axis=1)\n",
    "X_train_g = np.take(X_train, -1, axis=1)\n",
    "\n",
    "X_cal_no_g = np.delete(X_cal, -1, axis=1)\n",
    "X_cal_g = np.take(X_cal, -1, axis=1)\n",
    "\n",
    "X_test_no_g = np.delete(X_test, -1, axis=1)\n",
    "X_test_g = np.take(X_test, -1, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MSE:  0.115494594041\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "lr.fit(X_all_train_no_g, y_all_train)\n",
    "baseline_predict = lr.predict(X_test_no_g)\n",
    "\n",
    "print(\"Overall MSE: \",  mean_squared_error(y_test, baseline_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MSE:  0.120103869742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train_no_g, y_train)\n",
    "\n",
    "pred_cal = lr.predict(X_cal_no_g)\n",
    "pred_test = lr.predict(X_test_no_g)\n",
    "\n",
    "ir = IsotonicRegression( out_of_bounds = 'clip' )\n",
    "ir.fit(pred_cal, y_cal)\n",
    "test_cal = ir.transform(pred_test)\n",
    "\n",
    "print(\"Overall MSE: \",  mean_squared_error(y_test, test_cal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrated by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MSE:  0.12693162472\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train_no_g, y_train)\n",
    "\n",
    "pred_cal = lr.predict(X_cal_no_g)\n",
    "pred_test = lr.predict(X_test_no_g)\n",
    "\n",
    "#split into groups\n",
    "pred_cal0 = [x for i,x in enumerate(pred_cal) if X_cal_g[i]==0]\n",
    "pred_cal1 = [x for i,x in enumerate(pred_cal) if X_cal_g[i]==1]\n",
    "y_cal0 = [x for i,x in enumerate(y_cal) if X_cal_g[i]==0]\n",
    "y_cal1 = [x for i,x in enumerate(y_cal) if X_cal_g[i]==1]\n",
    "pred_test0 = [x for i,x in enumerate(pred_test) if X_test_g[i]==0]\n",
    "pred_test1 = [x for i,x in enumerate(pred_test) if X_test_g[i]==1]\n",
    "y_test0 = [x for i,x in enumerate(y_test) if X_test_g[i]==0]\n",
    "y_test1 = [x for i,x in enumerate(y_test) if X_test_g[i]==1]\n",
    "\n",
    "# Fit isotonic regression twice, once for each group\n",
    "ir = IsotonicRegression( out_of_bounds = 'clip' )\n",
    "ir.fit(pred_cal0, y_cal0)\n",
    "test_cal0 = ir.transform(pred_test0)\n",
    "\n",
    "ir.fit(pred_cal1, y_cal1)\n",
    "test_cal1 = ir.transform(pred_test1)\n",
    "\n",
    "print(\"Overall MSE: \",  (mean_squared_error(y_test0, test_cal0) + mean_squared_error(y_test1, test_cal1)) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
